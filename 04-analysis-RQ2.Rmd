---
title: 'CJ meta-analysis: RQ2'
author: "George Kinnear"
date: "2023-08-15"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.path='figs-web/04-analysis-RQ2/')
knitr::opts_chunk$set(dpi=300,fig.width=7)

# for plotting
theme_set(theme_minimal())

library(knitr)
library(kableExtra)
basic_kable = function(df, ...) {
  df %>% 
    kable(...) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)
}
```

# About the sample

```{r}
cj_sessions <- read_csv("data/00-judging_sessions_summary.csv", show_col_types = FALSE)
reliability_stats <- read_csv("data/01-meta-analysis-data.csv", show_col_types = FALSE)

meta_analysis_data <- cj_sessions %>% 
  left_join(reliability_stats, by = "judging_session")

meta_analysis_data %>% 
  summarise(n_datatsets = n_distinct(judging_session))
```

# Observed distribution of reliability measures

For these plots:

* Scale Separation Reliability (SSR) is the value of SSR computed from the item scores and standard errors using all of the available judgement data,
* Split-halves reliability comes from computing the Pearson correlation coefficient of the scores produced by fitting the Bradley-Terry model separately on two randomly-selected partitions of the judges, and taking the median of 100 such random splits,
* Correct comparisons is the proportion of individual decisions that agree with the final rank order of the items.

```{r}
observed_reliabilities <- meta_analysis_data %>% 
  select(judging_session, ssr, median_split_corr, prop_correct_judgements) %>% 
  pivot_longer(-judging_session, names_to = "measure", values_to = "value") %>% 
  mutate(measure = case_when(
    measure == "ssr" ~ "Scale Separation Reliability",
    measure == "median_split_corr" ~ "Split-halves reliability",
    measure == "prop_correct_judgements" ~ "Correct comparisons"
  )) %>% 
  mutate(measure = fct_relevel(measure, "Scale Separation Reliability", "Split-halves reliability", "Correct comparisons"))

plot_reliabilities <- observed_reliabilities %>% 
  ggplot(aes(x = measure, y = value)) +
  #Add individual observations to the plot
  geom_point(
    position = position_jitter(width=.3, seed = 123), # add jitter to the observations, using seed so it's reproducible
    alpha=.4, # set the size of each dot. alpha adds transparency
    color = "black", fill = "black") +
  geom_boxplot(width = 0.1, position = position_nudge(x = -0.5)) +
  #scale_y_continuous(trans='log10', labels = scales::comma, minor_breaks = rep(1:9, 21)*(10^rep(-10:10, each=9))) +
  facet_wrap(~ measure, scales = "free_y", ncol = 1) + 
  coord_flip() +
  labs(x = "", y = "") +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    # left align the headings
    strip.text.x = element_text(hjust = 0),
    # add space between the rows
    panel.spacing = unit(1, "lines"),
  )


plot_reliabilities +
  # add max/min/median: https://stackoverflow.com/a/55762626
  stat_summary(
    geom = "text",
    fun = quantile,
    fun.args = list(probs = c(0, 0.5, 1)), # don't need the 0.25 and 0.75!
    aes(label = sprintf("%1.02f", after_stat(y))),
    position = position_nudge(x = -0.8),
    size = 3,
    colour = "#999999"
  ) +
  expand_limits(x = -0.1) # stop the boxplot labels getting chopped off

ggsave("figs-pdf/FIG_RQ2-distribution.pdf", units = "cm", width = 15, height = 9)
```


## Relationship between observed measures

```{r, scatter, fig.height=6, fig.width=6}
plot_scatter <- observed_reliabilities %>%
  left_join(observed_reliabilities, by = "judging_session", relationship = "many-to-many") %>%
  filter(measure.x != measure.y) %>%
  filter(measure.x != "Correct comparisons") %>%
  filter(measure.y != "Scale Separation Reliability") %>%
  ggplot(aes(x = value.x, y = value.y)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", formula = "y ~ x", colour = "#003399", se = FALSE) +
  geom_abline(slope = 1, intercept = 0) +
  facet_grid(
    rows = vars(measure.y),
    cols = vars(measure.x),
    scales = "free",
    switch = "both"
  ) +
  labs(x = "", y = "") +
  lims(x = c(0,1), y = c(0,1)) +
  theme_minimal(base_size = 12) +
  theme(
    aspect.ratio = 1,
    # put the facet titles outside the y-axis ticks
    strip.placement = "outside",
    # add space between the panels
    panel.spacing = unit(2, "lines"),
  )

# kill off the unused top right panel! https://stackoverflow.com/a/49525552
grob <- ggplotGrob(plot_scatter);
# Remove facet
grob$grobs[[which(grob$layout$name %in% c("panel-1-2"))]] <- grid::nullGrob();
# Plot
grid::grid.newpage()
grid::grid.draw(grob)

ggsave("figs-pdf/FIG_RQ2-observed-scatterplot.pdf", plot = grob, units = "cm", width = 14, height = 14)
```


# Effect of N_CR on reliability measures

> TODO - decide which thresholds to use

```{r}
reliabilities_ncr <- observed_reliabilities %>% 
  left_join(cj_sessions %>% select(judging_session, observed_N_C, observed_N_R), join_by(judging_session)) %>% 
  mutate(N_CR = observed_N_C / observed_N_R, .keep = "unused")

reliabilities_ncr_plot_data <-
  bind_rows(
    "all" = reliabilities_ncr,
    "5+" = reliabilities_ncr %>% filter(N_CR >= 5),
    "10+" = reliabilities_ncr %>% filter(N_CR >= 10),
    "17+" = reliabilities_ncr %>% filter(N_CR >= 17),
    .id = "ncr"
  ) %>% 
  mutate(ncr = fct_relevel(ncr, "all", "5+", "10+", "17+"))

reliabilities_ncr_plot_data %>% 
  ggplot(aes(x = ncr, y = value)) +
  geom_point(
    position = position_jitter(width=.1, seed = 123), # add jitter to the observations, using seed so it's reproducible
    alpha=.2, # set the size of each dot. alpha adds transparency
    color = "black", fill = "black", size = 0.4) +
  geom_boxplot(width = 0.2, position = position_nudge(x = 0.3), linewidth = 0.3, outlier.size = 0.4) +
  facet_grid(cols = vars(measure)) +
  labs(y = "", x = "Number of comparisons per representation")

ggsave("figs-pdf/FIG_RQ2-varying-ncr.pdf", units = "cm", width = 14, height = 7)
```


```{r}
reliabilities_ncr <- observed_reliabilities %>% 
  left_join(cj_sessions %>% select(judging_session, observed_N_C, observed_N_R), join_by(judging_session)) %>% 
  mutate(N_CR = observed_N_C / observed_N_R, .keep = "unused")

reliabilities_ncr_plot_data <-
  bind_rows(
    "all" = reliabilities_ncr,
    "10+" = reliabilities_ncr %>% filter(N_CR >= 10),
    "20+" = reliabilities_ncr %>% filter(N_CR >= 20),
    "34+" = reliabilities_ncr %>% filter(N_CR >= 34),
    .id = "ncr"
  ) %>% 
  mutate(ncr = fct_relevel(ncr, "all", "10+", "20+", "34+"))

reliabilities_ncr_plot_data %>% 
  ggplot(aes(x = ncr, y = value)) +
  geom_point(
    position = position_jitter(width=.1, seed = 123), # add jitter to the observations, using seed so it's reproducible
    alpha=.2, # set the size of each dot. alpha adds transparency
    color = "black", fill = "black", size = 0.4) +
  geom_boxplot(width = 0.2, position = position_nudge(x = 0.3), linewidth = 0.3, outlier.size = 0.4) +
  facet_grid(cols = vars(measure)) +
  labs(y = "", x = "Number of comparisons per representation")

ggsave("figs-pdf/FIG_RQ2-varying-ncr.pdf", units = "cm", width = 14, height = 7)
```

```{r}
reliabilities_ncr_plot_data %>% 
  summarise(
    min = min(value),
    median = median(value),
    max = max(value),
    .by = c(ncr, measure)
  )
```



# Relationships between reliability measures

> TODO - single scatter plot version of Figure 6






