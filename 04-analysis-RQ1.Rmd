---
title: 'CJ meta-analysis: RQ1'
author: "George Kinnear"
date: "2023-08-15"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.path='figs-web/04-analysis-RQ1/')
knitr::opts_chunk$set(dpi=300,fig.width=7)

# for plotting
theme_set(theme_minimal())

library(knitr)
library(kableExtra)
basic_kable = function(df, ...) {
  df %>% 
    kable(...) %>%
    kable_styling(bootstrap_options = "striped", full_width = F)
}

apa2dp = function(x) {
  #formatC(x, digits = 2, format = "f") %>% str_replace(., "0\\.", ".")
  format(round(x, digits = 2), nsmall = 2) %>% str_replace('0.', '.')
}

# for correlations
library(rstatix)
```

# About the sample

```{r}
cj_sessions <- read_csv("data/00-judging_sessions_summary.csv", show_col_types = FALSE)
reliability_stats <- read_csv("data/01-meta-analysis-data.csv", show_col_types = FALSE)

meta_analysis_data <- cj_sessions %>% 
  left_join(reliability_stats, by = "judging_session")

meta_analysis_data %>% 
  summarise(n_datatsets = n_distinct(judging_session))
```

```{r}
rq1_data <- meta_analysis_data %>%
  select(judging_session, starts_with("observed_N_")) %>%
  pivot_longer(cols = starts_with("observed_N"), names_to = "feature", values_to = "count", names_prefix = "observed_N_") %>%
  mutate(feature = case_when(
    feature == "A" ~ "Assessors",
    feature == "R" ~ "Representations",
    feature == "C" ~ "Comparisons"
  ))

rq1_data_wide <- meta_analysis_data %>%
  select(judging_session, starts_with("observed_N_")) %>%
  rename(
    Assessors = observed_N_A,
    Representations = observed_N_R,
    Comparisons = observed_N_C
  )
```


# Judging session characteristics

```{r, counts, fig.height=3, fig.width=6}
plot_counts <- rq1_data %>% 
  # pivot_longer(cols = !judging_session, names_to = "feature", values_to = "count") %>% 
  ggplot(aes(x = feature, y = count)) +
  #Add individual observations to the plot
  geom_point(
    position = position_jitter(width=.3, seed = 123), # add jitter to the observations, using seed so it's reproducible
    size = 1, alpha=.3, # set the size of each dot. alpha adds transparency
    color = "black", fill = "black") +
  geom_boxplot(width = 0.3, position = position_nudge(x = -0.6)) +
  scale_y_continuous(trans='log10', labels = scales::comma, minor_breaks = rep(1:9, 21)*(10^rep(-10:10, each=9))) +
  facet_wrap(~ feature, scales = "free_y", ncol = 1) + 
  coord_flip() +
  labs(x = "", y = "") +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    # left align the headings
    strip.text.x = element_text(hjust = 0),
    # add space between the rows
    panel.spacing = unit(1, "lines"),
  )

plot_counts

ggsave("figs-pdf/FIG_RQ1-counts.pdf", units = "cm", width = 15, height = 9)

plot_counts +
  # add max/min/median: https://stackoverflow.com/a/55762626
  stat_summary(
    geom = "text",
    fun = quantile,
    fun.args = list(probs = c(0, 0.5, 1)), # don't need the 0.25 and 0.75!
    aes(label = sprintf("%1.0f", after_stat(y))),
    position = position_nudge(x = -1),
    size = 3,
    colour = "#999999"
  ) +
  expand_limits(x = -0.2) # stop the boxplot labels getting chopped off

ggsave("figs-pdf/FIG_RQ1-counts-labelled.pdf", units = "cm", width = 15, height = 9)

```

```{r}
meta_analysis_data %>% 
  mutate(N_A = case_when(
    observed_N_A <= 10 ~ "<= 10",
    observed_N_A <= 100 ~ "<= 100",
    observed_N_A <= 1000 ~ "<= 1000",
    .default = "1000+"
  )) %>% 
  janitor::tabyl(N_A, judge_expertise) %>% 
  basic_kable()
```

We can also consider the observed variance of the theta estimates for each judging session:

```{r}
variance_of_thetas_per_judging_session <- meta_analysis_data %>% 
  select(judging_session) %>% 
  mutate(path = str_glue("data-cache/{judging_session}/btm_results.csv")) %>% 
  pull(path) %>% 
  vroom::vroom(id = "path", show_col_types = FALSE) %>% 
  separate(path, into = c(NA, "judging_session", NA), sep = "/") %>% 
  summarise(theta_var = var(theta), .by = "judging_session")

variance_of_thetas_per_judging_session
```

```{r variance_of_thetas_per_judging_session}
variance_of_thetas_per_judging_session %>% 
  ggplot(aes(x = theta_var)) +
  geom_boxplot(position = position_nudge(y = -1)) +
  geom_histogram()
```



# Relationship between characteristics

```{r, scatter, fig.height=6, fig.width=6}
plot_scatter <- rq1_data %>%
  left_join(rq1_data, by = "judging_session", relationship = "many-to-many") %>%
  filter(feature.x != feature.y) %>%
  filter(feature.y != "Assessors") %>%
  filter(feature.x != "Representations") %>%
  ggplot(aes(x = count.x, y = count.y)) +
  geom_point(alpha = 0.4) +
  #geom_smooth(method = "lm", formula = "y ~ x", colour = "#003399", se = FALSE) +
  scale_y_continuous(trans = 'log10', labels = scales::comma) +
  scale_x_continuous(trans = 'log10', labels = scales::comma) +
  facet_grid(
    rows = vars(feature.y),
    cols = vars(feature.x),
    scales = "free",
    switch = "both"
  ) +
  labs(x = "", y = "") +
  theme_minimal(base_size = 11) +
  theme(
    aspect.ratio = 1,
    # put the facet titles outside the y-axis ticks
    strip.placement = "outside",
    # add space between the panels
    panel.spacing = unit(2, "lines"),
  )

# kill off the unused top right panel! https://stackoverflow.com/a/49525552
grob <- ggplotGrob(plot_scatter);
# Remove facet
grob$grobs[[which(grob$layout$name %in% c("panel-1-2"))]] <- grid::nullGrob();
# Plot
grid::grid.newpage()
grid::grid.draw(grob)

ggsave("figs-pdf/FIG_RQ1-scatterplot.pdf", plot = grob, units = "cm", width = 12, height = 12)
```

Here we show all three variables in their raw scales, with Pearson correlations in the lower cells:

```{r}
library(GGally)

# thanks to https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-metric-predictors.html
show_corr <- function(data, mapping, ...) {
  
  # get the x and y data to use the other code
  x <- eval_data_col(data, mapping$x)
  y <- eval_data_col(data, mapping$y)
  
  # compute the correlations
  corr <- cor.test(x, y, method = "p", use = "pairwise")
  
  # plot the cor value
  ggally_text(
    label = corr$estimate %>% apa2dp(),
    mapping = aes(),
    color = "black",
    size = 3) +
    cowplot::panel_border(size = ifelse(corr$p.value < 0.05, 1, 1/2), color = ifelse(corr$p.value < 0.05, "steelblue4", "grey85"))
}

show_scatter <- function(data, mapping, ...) {
  
  # get the x and y data to use the other code
  x <- eval_data_col(data, mapping$x)
  y <- eval_data_col(data, mapping$y)
  
  # compute the correlations
  corr <- cor.test(x, y, method = "p", use = "pairwise")
  
  ggplot(data = data, mapping = mapping) + 
    #geom_point(size = .75, shape = 21, stroke = 1/10,
    #           color = "white", fill = "steelblue4") +
    geom_point(size = .75, stroke = 0, color = "steelblue4", alpha = 0.3) +
    cowplot::panel_border(size = ifelse(corr$p.value < 0.05, 1, 1/2), color = ifelse(corr$p.value < 0.05, "steelblue4", "grey85"))
}

show_dist <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) + 
    geom_histogram(bins = 30) +
    cowplot::panel_border(size = 1/2)
}

rq1_data %>% 
  pivot_wider(names_from = feature, values_from = count) %>% 
  select(-judging_session) %>% 
  ggpairs(
    upper = list(continuous = show_scatter),
    lower = list(continuous = show_corr),
    diag = list(continuous = show_dist),
    progress = FALSE
  ) +
  theme(
    strip.text = element_text(size = 6),
    strip.text.y.right = element_text(angle = 0),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

ggsave("figs-pdf/FIG_RQ1_all-correlations.pdf", units = "cm", width = 12, height = 11.5)
```

Correlations (Spearman):

```{r}
cor.test(rq1_data_wide$Assessors, rq1_data_wide$Comparisons, method = "spearman")
cor.test(rq1_data_wide$Assessors, rq1_data_wide$Representations, method = "spearman")
cor.test(rq1_data_wide$Comparisons, rq1_data_wide$Representations, method = "spearman")
```

Try some more elaborate methods for computing correlations:

```{r}
rq1_data_wide %>% select(!judging_session) %>%
  rstatix::cor_test(
    method = "spearman"
  ) %>% 
  filter(var1 < var2) %>%
  select(-method) %>% 
  basic_kable()
```


## Special N_CR plot

There is a linear relationship in the log-log plot of N_C vs N_R, which means there is a relationship of the form $\log_{10} N_C = \beta_1\log_{10} N_R+\beta_0$, i.e. $N_C = 10^{\beta_0} N_R^{\beta_1}$

```{r}
ncr_lm <- rq1_data %>%
  filter(feature %in% c("Representations", "Comparisons")) %>% 
  pivot_wider(names_from = feature, values_from = count) %>% 
  mutate(Representations = log10(Representations)) %>% 
  mutate(Comparisons = log10(Comparisons)) %>% 
  lm(data = ., formula = Comparisons ~ Representations)

ncr_lm %>% 
  summary()
```

Here we compute some values predicted by the linear regression (red points) and check that they match up with the plot from before:

```{r}
pred_interval <- tibble(Representations = seq(1, 3, by = 0.01))
prediction_interval_data <- bind_cols(
  pred_interval, predict(ncr_lm, new = pred_interval, se.fit = TRUE, interval = "prediction")$fit
  ) %>% 
  mutate(across(everything(), ~ 10^(.x)))

rq1_data %>%
  left_join(rq1_data, by = "judging_session", relationship = "many-to-many") %>%
  filter(feature.x == "Representations") %>%
  filter(feature.y == "Comparisons") %>%
  ggplot(aes(x = count.x, y = count.y)) +
  geom_point(alpha = 0.4) +
  geom_point(data = prediction_interval_data, aes(x = Representations, y = fit), colour = "red") +
  geom_smooth(method = "lm", formula = "y ~ x", colour = "#003399", se = FALSE) +
  scale_y_continuous(trans = 'log10', labels = scales::comma) +
  scale_x_continuous(trans = 'log10', labels = scales::comma) +
  facet_grid(
    rows = vars(feature.y),
    cols = vars(feature.x),
    scales = "free",
    switch = "both"
  ) +
  labs(x = "", y = "") +
  expand_limits(x = 1, y = 1) +
  theme_minimal(base_size = 12) +
  theme(
    aspect.ratio = 1,
    # put the facet titles outside the y-axis ticks
    strip.placement = "outside",
    # add space between the panels
    panel.spacing = unit(2, "lines"),
  )
```

Here is what it looks like on the non-transformed axes (restricted to $N_R<1000$):

```{r}
rq1_data %>%
  left_join(rq1_data, by = "judging_session", relationship = "many-to-many") %>%
  filter(feature.x == "Representations") %>%
  filter(feature.y == "Comparisons") %>%
  filter(count.x < 1000) %>% 
  ggplot(aes(x = count.x, y = count.y)) +
  geom_point(data = prediction_interval_data, aes(x = Representations, y = fit), colour = "red", alpha = 0.2) +
  geom_function(fun = ~ 10^(2.145892)*(.x)^0.5345649, colour = "red") +
  geom_point(alpha = 0.4) +
  facet_grid(
    rows = vars(feature.y),
    cols = vars(feature.x),
    scales = "free",
    switch = "both"
  ) +
  labs(x = "", y = "") +
  expand_limits(x = 1, y = 1) +
  theme_minimal(base_size = 12) +
  theme(
    aspect.ratio = 1,
    # put the facet titles outside the y-axis ticks
    strip.placement = "outside",
    # add space between the panels
    panel.spacing = unit(2, "lines"),
  )
```



# Derived characteristics

Now we look at ratios of the session characteristics.

```{r, derived-counts-data}
rq1_data_derived_wide <- rq1_data_wide %>% 
  mutate(N_RA = Representations / Assessors,
         N_CR = 2 * Comparisons / Representations,
         N_CA = Comparisons / Assessors) %>% 
  select(judging_session, starts_with("N_"))

rq1_data_derived <- pivot_longer(rq1_data_derived_wide, starts_with("N_"), names_to = "feature", values_to = "count") %>% 
  mutate(feature = case_when(
    feature == "N_RA" ~ "Representations per assessor",
    feature == "N_CR" ~ "Comparisons per representation",
    feature == "N_CA" ~ "Comparisons per assessor"
  ))
```



```{r, derived-counts, fig.height=3, fig.width=6}
plot_derived_counts <- rq1_data_derived %>% 
  # pivot_longer(cols = !judging_session, names_to = "feature", values_to = "count") %>% 
  ggplot(aes(x = feature, y = count)) +
  #Add individual observations to the plot
  geom_point(
    position = position_jitter(width=.3, seed = 123), # add jitter to the observations, using seed so it's reproducible
    size = 1, alpha=.3, # set the size of each dot. alpha adds transparency
    color = "black", fill = "black") +
  geom_boxplot(width = 0.3, position = position_nudge(x = -0.6)) +
  scale_y_continuous(trans='log10', labels = scales::comma, minor_breaks = rep(1:9, 21)*(10^rep(-10:10, each=9))) +
  facet_wrap(~ feature, scales = "free", ncol = 1) + 
  coord_flip() +
  labs(x = "", y = "") +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    # left align the headings
    strip.text.x = element_text(hjust = 0),
    # add space between the rows
    panel.spacing = unit(1, "lines"),
  )

plot_derived_counts

ggsave("figs-pdf/FIG_RQ1-derived-counts.pdf", units = "cm", width = 15, height = 9)

plot_derived_counts +
  # add max/min/median: https://stackoverflow.com/a/55762626
  stat_summary(
    geom = "text",
    fun = quantile,
    fun.args = list(probs = c(0, 0.5, 1)), # don't need the 0.25 and 0.75!
    aes(label = sprintf("%1.02f", after_stat(y))),
    position = position_nudge(x = -1),
    size = 3,
    colour = "#999999"
  ) +
  expand_limits(x = -0.2) # stop the boxplot labels getting chopped off

ggsave("figs-pdf/FIG_RQ1-derived-counts-labelled.pdf", units = "cm", width = 15, height = 9)

```

Top 3:

```{r}
rq1_data_derived %>% 
  group_by(feature) %>% 
  slice_max(count, n = 3) %>% 
  basic_kable()
```

Bottom 3:

```{r}
rq1_data_derived %>% 
  group_by(feature) %>% 
  slice_min(count, n = 3) %>% 
  basic_kable()
```

Proportion below certain levels:

```{r}
rq1_data_derived %>% 
  summarise(
    prop_below_10 = sum(count <= 10) / n(),
    prop_below_100 = sum(count <= 100) / n(),
    .by = "feature"
  ) %>% 
  mutate(across(starts_with("prop_"), ~ scales::percent(.x, accuracy = 0.1))) %>% 
  basic_kable()
```

```{r}
rq1_data_derived %>% 
  filter(feature == "Comparisons per representation") %>% 
  summarise(
    prop_above_10 = sum(count >= 10) / n(),
    prop_above_20 = sum(count >= 20) / n(),
    prop_above_37 = sum(count >= 37) / n(),
    .by = "feature"
  ) %>% 
  mutate(across(starts_with("prop_"), ~ scales::percent(.x, accuracy = 0.1))) %>% 
  basic_kable()
```

