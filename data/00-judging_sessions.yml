# - project_id: AuthorYear citation key
#   citation: APA formatted citation
#   doi: 10.xxxx/yyyyyyyyyyyyy
#   open_data:
#        Link to the publicly-available dataset
#        N = not published publicly
#   republish: Y/N according to whether processed judging data can be included in our open dataset
#   judging_sessions:
#    - study: identifier for the CJ session
#    - N_A: number of assessors (i.e. judges)
#      N_R: number of representations (i.e. scripts)
#      N_J: total number of judgements
#      items: short description of what is being judged
#      judge_expertise:
#            expert = judges are teachers/researchers with relevant expertise
#            peer = judges are drawn from the group of people who produced the representations, typically students doing peer assessment
#            novice = judges have little or no domain-specific expertise, and have not produced their own representations
#      judging_prompt: what the judges were asked to base their decisions on

 - project_id: Bramley_2019
   citation: Bramley, T., & Vitello, S. (2019). The effect of adaptivity on the reliability coefficient in adaptive comparative judgement. Assessment in Education: Principles, Policy & Practice, 26(1), 43–58. 
   doi: 10.1080/0969594X.2017.1418734
   open_data: N
   republish: Y
   judging_sessions:
    - study: ALLPLAYALL (Bramley: this has the data for the all-play-all, excluding the data from one of the judges (judge 19) who it says on p49 of Bramley & Vitello (2019) we excluded for implausibly fast judgements.  20 scripts and 17 judges in total.).
    - N_A: 18
      N_R: 20
      N_J: 180
    - study: ACJ (Bramley: this has the data for the adaptive study.  Same judges, no exclusions.  150 scripts (including the 20 from the all-play-all) and 18 judges in total (same judges as the all-play-all)).
    - N_A: 18
      N_R: 150
      N_J: 1079
    - study: RANDOM (Bramley: this has the data for the ‘random’ (but chosen in advance) study.  The same 150 scripts but 16 different judges.).
    - N_A: 16
      N_R: 150
      N_J: 1097
      items: GCSE English autobiographical essays (real scripts)
      judge_expertise: expert
      judging_prompt: "Which essay is better?"
      author_note: there are some apparently missing judge numbers – I think this was judges who dropped out of the study

 
 - project_id: Coertjens_2021
   citation: Coertjens, L., Lesterhuis, M., De Winter, B. Y., Goossens, M., De Maeyer, S., & Michels, N. R. (2021). Improving Self-Reflection Assessment Practices: Comparative Judgment as an Alternative to Rubrics. Teaching and Learning in Medicine, 1-11.
   doi: 10.1080/10401334.2021.1877709
   open_data: https://zenodo.org/record/3746671#.YRZqB8ozaUk
   republish: Y
   judging_sessions:
    - N_A: 8
      N_R: 22
      N_J: 202
      items: written self-reflections by medical students
      judge_expertise: expert
      judging_prompt: "Which is the better self-reflection?"
      
 - project_id: Holmes_2017
   citation: Holmes, S. D., He, Q., & Meadows, M. (2017). An investigation of construct relevant and irrelevant features of mathematics problem-solving questions using comparative judgement and Kelly’s Repertory Grid. Research in Mathematics Education, 19(2), 112–129.
   doi: 10.1080/14794802.2017.1334576
   open_data: N
   republish: Y
   judging_sessions:
    - N_A: 33
      N_R: 66
      N_J: 1650
      items: secondary school students' mathematics problem solving responses
      judge_expertise: expert
      judging_prompt: "Which item best elicits mathematical problem-solving as described by AO3?"
      
 - project_id: Holmes_2018
   citation: Holmes, S. D., Meadows, M., Stockford, I., & He, Q. (2018). Investigating the comparability of examination difficulty using comparative judgement and Rasch modelling. International Journal of Testing, 18, 366–391.
   doi: 10.1080/15305058.2018.1486316
   open_data: N
   republish: Y
   judging_sessions:
    - N_A: 43
      N_R: 2150
      N_J: 35000
      items: GCSE mathematics items (not responses)
      judge_expertise: expert
      judging_prompt: “Which Item is the More Mathematically Difficult to Answer Fully?"

- project_id: Jones2015
  citation: Jones, I., Swan, M., & Pollitt, A. (2015). Assessing mathematical problem solving using comparative judgement. International Journal of Science and Mathematics Education, 13(1), 151-177.
  doi: 10.1007/s10763-013-9497-6
  open_data: N
  republish: Y
  judging_sessions:
    - study: Bowland030211data
      N_A: 12
      N_R: 18
      items: scripts with solutions to 3 Bowland tasks
      judge_expertise: expert
      note: "TODO: should this be combined with Bowland070211data?"
    - study: Bowland070211data
      N_A: 11
      N_R: 18
      items: scripts with solutions to 3 Bowland tasks
      judge_expertise: expert
    - study: GCSE030211data   
      N_A: 12
      N_R: 18
      items: scripts from GCSE exams
      judge_expertise: expert
      note: "TODO: should this be combined with GCSE070211data?"
    - study: GCSE070211data
      N_A: 11
      N_R: 18
      items: scripts from GCSE exams
      judge_expertise: expert

- project_id: Jones2014
  citation: Jones, I., & Alcock, L. (2014). Peer assessment without assessment criteria. Studies in Higher Education, 39(10), 1774-1787.
  doi: 10.1080/03075079.2013.821974
  open_data: N
  republish: Y
  judging_sessions:
    - study: expert1
      N_A: 11
      N_R: 168
      items: answers to a conceptual question
      judge_expertise: expert
      note: "TODO: combine with expert2?"
    - study: expert2
      N_A: 11
      N_R: 168
      items: answers to a conceptual question
      judge_expertise: expert
    - study: novice
      N_A: 9
      N_R: 168
      items: answers to a conceptual question
      judge_expertise: novice
    - study: peer1
      N_A: 100
      N_R: 168
      items: answers to a conceptual question
      judge_expertise: peer
      note: "TODO: combine with peer2?"
    - study: peer2
      N_A: 93
      N_R: 168
      items: answers to a conceptual question
      judge_expertise: peer

- project_id: McMahon2015
  citation: "McMahon, S., & Jones, I. (2015). A comparative judgement approach to teacher assessment. Assessment in Education: Principles, Policy & Practice, 22(3), 368-389."
  doi: 10.1080/0969594X.2014.978839
  open_data: N
  republish: Y
  judging_sessions:
  - study: expert
    N_A: 5
    N_R: 154
    items: writeup of a science investigation by 14-15-year-olds
    judge_expertise: expert
    note: "TODO: GET THIS DATA!"
  - study: peer
    N_A: 37
    N_R: 154
    items: writeup of a science investigation by 14-15-year-olds
    judge_expertise: peer
 
- project_id: Jones2015b
  citation: "Jones, I., & Wheadon, C. (2015). Peer assessment using comparative and absolute judgement. Studies in Educational Evaluation, 47, 93–101."
  doi: 10.1016/j.stueduc.2015.09.004
  open_data: N
  republish: Y
  judging_sessions:
  - N_A: 76
    N_R: 24
    items: answers to a question about fractions
    judge_expertise: novice
 
- project_id: Bisson2019
  citation: "Bisson, M.-J., Gilmore, C., Inglis, M., & Jones, I. (2019). Teaching using contextualised and decontextualised representations: examining the case of differential calculus through a comparative judgement technique. Research in Mathematics Education, 1–20."
  doi: 10.1080/14794802.2019.1692060
  open_data: "https://doi.org/10.17028/rd.lboro.5845683.v1"
  republish: Y
  judging_sessions:
  - N_A: 10
    N_R: 189
    items: responses to an open-ended question about derivatives
    judge_expertise: expert

- project_id: Jones2013
  citation: "Jones, I., Inglis, M., Gilmore, C., & Hodgen, J. (2013). Measuring conceptual understanding: The case of fractions. In A. M. Lindmeier & A. Heinze (Eds.), Proceedings of the 37th Conference of the International Group for the Psychology of Mathematics Education (Vol. 3, pp. 113–120). Kiel, Germany: PME. Retrieved from https://hdl.handle.net/2134/12828"
  open_data: N
  republish: Y
  judging_sessions:
  - N_A: 8
    N_R: 25
    items: answers to a question about fractions
    judge_expertise: expert

- project_id: Bisson2016
  citation: "Bisson, M.-J., Gilmore, C., Inglis, M., & Jones, I. (2016). Measuring Conceptual Understanding Using Comparative Judgement. International Journal of Research in Undergraduate Mathematics Education, 2(2), 141–164."
  doi: 10.1007/s40753-016-0024-3
  open_data: N
  republish: Y
  judging_sessions:
  - study: stats
    N_A: 10
    N_R: 20
    items: written explanation of p-value
    judge_expertise: expert
  - study: calculus
    N_A: 30
    N_R: 42
    items: written explanation of derivatives
    judge_expertise: expert
    note: "TODO: two participants were removed from analyses - check value for N_A, should it be 28?"
  - study: algebra
    N_A: 10
    N_R: 46
    items: written explanation of how letters are used in algebra
    judge_expertise: expert

- project_id: Davies2020
  citation: "Davies, B., Alcock, L., & Jones, I. (2020). Comparative judgement, proof summaries and proof comprehension. Educational Studies in Mathematics, 105(2), 181–197."
  doi: 10.1007/s10649-020-09984-x
  open_data: "https://doi.org/10.17028/rd.lboro.8940149.v1"
  republish: Y
  judging_sessions:
  - N_A: 11
    N_R: 143
    items: written summaries of a proof
    judge_expertise: expert

- project_id: Jones2019
  citation: "Jones, I., Bisson, M., Gilmore, C., & Inglis, M. (2019). Measuring conceptual understanding in randomised controlled trials: Can comparative judgement help? British Educational Research Journal, 45(3), 662–680."
  doi: 10.1002/berj.3519
  open_data: "https://repository.lboro.ac.uk/s/2d4cfa142ebf1ff24841"
  republish: Y
  judging_sessions:
  - N_A: 10
    N_R: 188
    items: written explanation of how letters are used in algebra
    judge_expertise: expert

- project_id: Jones2016
  citation: "Jones, I., Wheadon, C., Humphries, S., & Inglis, M. (2016). Fifty years of A-level mathematics: have standards changed? British Educational Research Journal, 42(4), 543–560."
  doi: 10.1002/BERJ.3224
  open_data: N
  republish: Y
  judging_sessions:
  - study: scripts
    N_A: 20
    N_R: 546
    items: individual question responses to various A-Level exam questions
    judge_expertise: expert
    note: "TODO: get this data!"
  - study: perfect
    N_A: 18
    N_R: 48
    items: model answers for various A-Level exam questions
    judge_expertise: expert
    
